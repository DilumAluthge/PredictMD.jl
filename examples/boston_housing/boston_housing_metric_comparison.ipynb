{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Regression Models\n",
    "\n",
    "* This assumes you have trained and save linear-regression, svm and mlp packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MersenneTwister(UInt32[0x000003e7], Base.dSFMT.DSFMT_state(Int32[-412893719, 1072748155, -748568654, 1073610384, -1271302057, 1073556021, -429186579, 1073162675, 932796209, 1073458022  …  1115928124, 1073598513, 1280798571, 1072732908, -581554620, 1977796709, 1774936613, -1100988421, 382, 0]), [1.62319, 1.35281, 1.03829, 1.06242, 1.31737, 1.67826, 1.16578, 1.98973, 1.90715, 1.53549  …  1.16349, 1.38708, 1.88594, 1.3401, 1.06464, 1.90276, 1.52995, 1.91265, 1.4553, 1.6623], 382)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import required packages\n",
    "import AluthgeSinhaBase\n",
    "const asb = AluthgeSinhaBase\n",
    "import CSV\n",
    "import DataFrames\n",
    "import GZip\n",
    "import StatsBase\n",
    "\n",
    "# set the seed of the global random number generator\n",
    "# this makes the results reproducible\n",
    "srand(999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Compare performance of all models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "\n",
    "# Import Boston housing data\n",
    "df = CSV.read(\n",
    "    GZip.gzopen(joinpath(Pkg.dir(\"RDatasets\"),\"data\",\"MASS\",\"Boston.csv.gz\")),\n",
    "    DataFrames.DataFrame,\n",
    "    )\n",
    "\n",
    "# Remove rows with missing data\n",
    "DataFrames.dropmissing!(df)\n",
    "\n",
    "# Shuffle rows\n",
    "asb.shufflerows!(df)\n",
    "\n",
    "# Define labels\n",
    "featurenames = Symbol[\n",
    "    :Crim,\n",
    "    :Zn,\n",
    "    :Indus,\n",
    "    :Chas,\n",
    "    :NOx,\n",
    "    :Rm,\n",
    "    :Age,\n",
    "    :Dis,\n",
    "    :Rad,\n",
    "    :Tax,\n",
    "    :PTRatio,\n",
    "    :Black,\n",
    "    :LStat,\n",
    "    ]\n",
    "\n",
    "labelname = :MedV\n",
    "\n",
    "# Put features and labels in separate dataframes\n",
    "featuresdf = df[featurenames]\n",
    "labelsdf = df[[labelname]]\n",
    "\n",
    "# Split data into training set (70%) and testing set (30%)\n",
    "trainingfeaturesdf,testingfeaturesdf,traininglabelsdf,testinglabelsdf =\n",
    "    asb.train_test_split(featuresdf,labelsdf;training = 0.7,testing = 0.3,);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mLoaded model from file ./linearreg.jld2\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "# load pre-trained models\n",
    "linearreg_filename = \"./linearreg.jld2\"\n",
    "\n",
    "# Set up linear regression model\n",
    "linearreg = asb.singlelabeldataframelinearregression(\n",
    "    featurenames,\n",
    "    labelname;\n",
    "    package = :GLMjl,\n",
    "    intercept = true, # optional, defaults to true\n",
    "    name = \"Linear regression\", # optional\n",
    "    )\n",
    "asb.load!(linearreg_filename, linearreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mLoaded model from file ./randomforestreg.jld2\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "# Set up random forest regression model\n",
    "randomforestreg_filename = \"./randomforestreg.jld2\"\n",
    "\n",
    "randomforestreg = asb.singlelabeldataframerandomforestregression(\n",
    "    featurenames,\n",
    "    labelname;\n",
    "    nsubfeatures = 2, # number of subfeatures; defaults to 2\n",
    "    ntrees = 20, # number of trees; defaults to 10\n",
    "    package = :DecisionTreejl,\n",
    "    name = \"Random forest\" # optional\n",
    "    )\n",
    "asb.load!(randomforestreg_filename, randomforestreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mLoaded model from file ./epsilonsvr_svmreg.jld2\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "# Set up epsilon-SVR model\n",
    "epsilonsvr_svmreg_filename = \"./epsilonsvr_svmreg.jld2\"\n",
    "\n",
    "epsilonsvr_svmreg = asb.singlelabeldataframesvmregression(\n",
    "    featurenames,\n",
    "    labelname;\n",
    "    package = :LIBSVMjl,\n",
    "    svmtype = LIBSVM.EpsilonSVR,\n",
    "    name = \"SVM (epsilon-SVR)\",\n",
    "    kernel = LIBSVM.Kernel.Linear,\n",
    "    verbose = false,\n",
    "    )\n",
    "asb.load!(epsilonsvr_svmreg_filename, epsilonsvr_svmreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mLoaded model from file ./nusvr_svmreg.jld2\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "# Set up nu-SVR model\n",
    "nusvr_svmreg_filename = \"./nusvr_svmreg.jld2\"\n",
    "nusvr_svmreg = asb.singlelabeldataframesvmregression(\n",
    "    featurenames,\n",
    "    labelname;\n",
    "    package = :LIBSVMjl,\n",
    "    svmtype = LIBSVM.NuSVR,\n",
    "    name = \"SVM (nu-SVR)\",\n",
    "    kernel = LIBSVM.Kernel.Linear,\n",
    "    verbose = false,\n",
    "    )\n",
    "asb.load!(nusvr_svmreg_filename, nusvr_svmreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mLoaded model from file ./knetmlpreg.jld2\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up multilayer perceptron model\n",
    "knetmlpreg_filename = \"./knetmlpreg.jld2\"\n",
    "\n",
    "#This should be defined somewhere else\n",
    "\n",
    "# Define predict function\n",
    "function knetmlp_predict(\n",
    "        w, # don't put a type annotation on this\n",
    "        x0::AbstractArray;\n",
    "        training::Bool = false,\n",
    "        )\n",
    "    # x0 = input layer\n",
    "    # x1 = hidden layer\n",
    "    x1 = Knet.relu.( w[1]*x0 .+ w[2] ) # w[1] = weights, w[2] = biases\n",
    "    # x2 = output layer\n",
    "    x2 = w[3]*x1 .+ w[4] # w[3] = weights, w[4] = biases\n",
    "    return x2\n",
    "end\n",
    "\n",
    "# Define loss function\n",
    "function knetmlp_loss(\n",
    "        predict::Function,\n",
    "        modelweights, # don't put a type annotation on this\n",
    "        x::AbstractArray,\n",
    "        ytrue::AbstractArray;\n",
    "        L1::Real = Cfloat(0),\n",
    "        L2::Real = Cfloat(0),\n",
    "        )\n",
    "    loss = mean(\n",
    "        abs2,\n",
    "        ytrue - predict(modelweights, x),\n",
    "        )\n",
    "    if L1 != 0\n",
    "        loss += L1 * sum(sum(abs, w_i) for w_i in modelweights[1:2:end])\n",
    "    end\n",
    "    if L2 != 0\n",
    "        loss += L2 * sum(sum(abs2, w_i) for w_i in modelweights[1:2:end])\n",
    "    end\n",
    "    return loss\n",
    "end\n",
    "\n",
    "# Define loss hyperparameters\n",
    "knetmlp_losshyperparameters = Dict()\n",
    "knetmlp_losshyperparameters[:L1] = Cfloat(0.0)\n",
    "knetmlp_losshyperparameters[:L2] = Cfloat(0.0)\n",
    "\n",
    "# Select optimization algorithm\n",
    "knetmlp_optimizationalgorithm = :Adam\n",
    "\n",
    "# Set optimization hyperparameters\n",
    "knetmlp_optimizerhyperparameters = Dict()\n",
    "\n",
    "# Set the minibatch size\n",
    "knetmlp_minibatchsize = 48\n",
    "\n",
    "# Set the max number of epochs. After training, look at the learning curve. If\n",
    "# it looks like the model has not yet converged, raise maxepochs. If it looks\n",
    "# like the loss has hit a plateau and you are worried about overfitting, lower\n",
    "# maxepochs.\n",
    "knetmlp_maxepochs = 500\n",
    "\n",
    "knetmlp_modelweights = Any[]\n",
    "\n",
    "knetmlpreg = asb.singlelabeldataframeknetregression(\n",
    "    featurenames,\n",
    "    labelname;\n",
    "    package = :Knetjl,\n",
    "    name = \"Knet MLP\",\n",
    "    predict = knetmlp_predict,\n",
    "    loss = knetmlp_loss,\n",
    "    losshyperparameters = knetmlp_losshyperparameters,\n",
    "    optimizationalgorithm = knetmlp_optimizationalgorithm,\n",
    "    optimizerhyperparameters = knetmlp_optimizerhyperparameters,\n",
    "    minibatchsize = knetmlp_minibatchsize,\n",
    "    modelweights = knetmlp_modelweights,\n",
    "    maxepochs = knetmlp_maxepochs,\n",
    "    printlosseverynepochs = 100, # if 0, will not print at all\n",
    "    )\n",
    "asb.load!(knetmlpreg_filename, knetmlpreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1×6 DataFrames.DataFrame\n",
      "│ Row │ metric                             │ Linear regression │ Random forest │ SVM (epsilon-SVR) │ SVM (nu-SVR) │ Knet MLP │\n",
      "├─────┼────────────────────────────────────┼───────────────────┼───────────────┼───────────────────┼──────────────┼──────────┤\n",
      "│ 1   │ R^2 (coefficient of determination) │ 0.800524          │ 0.929843      │ -6.30321          │ -6.30321     │ 0.731002 │1×6 DataFrames.DataFrame\n",
      "│ Row │ metric                             │ Linear regression │ Random forest │ SVM (epsilon-SVR) │ SVM (nu-SVR) │ Knet MLP │\n",
      "├─────┼────────────────────────────────────┼───────────────────┼───────────────┼───────────────────┼──────────────┼──────────┤\n",
      "│ 1   │ R^2 (coefficient of determination) │ 0.59293           │ 0.699748      │ -5.42347          │ -5.42347     │ 0.553721 │"
     ]
    }
   ],
   "source": [
    "# Compare performance of all five models on training set\n",
    "showall(asb.singlelabelregressionmetrics(\n",
    "    [\n",
    "        linearreg,\n",
    "        randomforestreg,\n",
    "        epsilonsvr_svmreg,\n",
    "        nusvr_svmreg,\n",
    "        knetmlpreg,\n",
    "        ],\n",
    "    trainingfeaturesdf,\n",
    "    traininglabelsdf,\n",
    "    labelname,\n",
    "    ))\n",
    "\n",
    "# Compare performance of all models on testing set\n",
    "showall(asb.singlelabelregressionmetrics(\n",
    "    [\n",
    "        linearreg,\n",
    "        randomforestreg,\n",
    "        epsilonsvr_svmreg,\n",
    "        nusvr_svmreg,\n",
    "        knetmlpreg,\n",
    "        ],\n",
    "    testingfeaturesdf,\n",
    "    testinglabelsdf,\n",
    "    labelname,\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
