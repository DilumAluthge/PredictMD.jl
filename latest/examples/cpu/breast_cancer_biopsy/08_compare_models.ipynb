{
 "cells": [
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mAttempting to load model...\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mLoaded model from file \"/tmp/tmpf7gfRC/PREDICTMDTEMPDIRECTORY/logistic_classifier.jld2\"\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mAttempting to load model...\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mLoaded model from file \"/tmp/tmpf7gfRC/PREDICTMDTEMPDIRECTORY/random_forest_classifier.jld2\"\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mAttempting to load model...\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mLoaded model from file \"/tmp/tmpf7gfRC/PREDICTMDTEMPDIRECTORY/c_svc_svm_classifier.jld2\"\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mAttempting to load model...\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mLoaded model from file \"/tmp/tmpf7gfRC/PREDICTMDTEMPDIRECTORY/nu_svc_svm_classifier.jld2\"\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mAttempting to load model...\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mLoaded model from file \"/tmp/tmpf7gfRC/PREDICTMDTEMPDIRECTORY/knet_mlp_classifier.jld2\"\n",
      "\u001b[39mWARNING: Method definition knetmlp_predict(Any, AbstractArray{T, N} where N where T) in module PredictMD at none:6 overwritten at none:6.\n",
      "WARNING: Method definition #knetmlp_predict(Array{Any, 1}, typeof(PredictMD.knetmlp_predict), Any, AbstractArray{T, N} where N where T) in module PredictMD overwritten.\n",
      "WARNING: Method definition knetmlp_loss(Function, Any, AbstractArray{T, N} where N where T, AbstractArray{T, N} where N where T) in module PredictMD at none:9 overwritten at none:9.\n",
      "WARNING: Method definition #knetmlp_loss(Array{Any, 1}, typeof(PredictMD.knetmlp_loss), Function, Any, AbstractArray{T, N} where N where T, AbstractArray{T, N} where N where T) in module PredictMD overwritten.\n",
      "\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36m12×6 DataFrames.DataFrame. Omitted printing of 4 columns\n",
      "│ Row │ metric                                           │ Logistic regression │\n",
      "├─────┼──────────────────────────────────────────────────┼─────────────────────┤\n",
      "│ 1   │ AUPRC                                            │ 0.990361            │\n",
      "│ 2   │ AUROCC                                           │ 0.995607            │\n",
      "│ 3   │ Average precision                                │ 0.990415            │\n",
      "│ 4   │ * Threshold                                      │ 0.672809            │\n",
      "│ 5   │ * Accuracy                                       │ 0.967742            │\n",
      "│ 6   │ * Cohen's Kappa statistic                        │ 0.912352            │\n",
      "│ 7   │ * F1 Score                                       │ 0.956175            │\n",
      "│ 8   │ * Precision (positive predictive value)          │ 0.96                │\n",
      "│ 9   │ * Negative predictive value                      │ 0.972222            │\n",
      "│ 10  │ * Recall (sensitivity, true positive rate)       │ 0.952381            │\n",
      "│ 11  │ [fix] * Sensitivity (recall, true positive rate) │ 0.952381            │\n",
      "│ 12  │ * Specificity (true negative rate)               │ 0.976744            │\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36m12×6 DataFrames.DataFrame. Omitted printing of 4 columns\n",
      "│ Row │ metric                                     │ Logistic regression │\n",
      "├─────┼────────────────────────────────────────────┼─────────────────────┤\n",
      "│ 1   │ AUPRC                                      │ 0.990361            │\n",
      "│ 2   │ AUROCC                                     │ 0.995607            │\n",
      "│ 3   │ Average precision                          │ 0.990415            │\n",
      "│ 4   │ * Threshold                                │ 0.254932            │\n",
      "│ 5   │ * Accuracy                                 │ 0.970674            │\n",
      "│ 6   │ * Cohen's Kappa statistic                  │ 0.923775            │\n",
      "│ 7   │ * F1 Score                                 │ 0.961832            │\n",
      "│ 8   │ * Precision (positive predictive value)    │ 0.926471            │\n",
      "│ 9   │ * Negative predictive value                │ 1.0                 │\n",
      "│ 10  │ * Recall (sensitivity, true positive rate) │ 1.0                 │\n",
      "│ 11  │ * Sensitivity (recall, true positive rate) │ 1.0                 │\n",
      "│ 12  │ [fix] * Specificity (true negative rate)   │ 0.953488            │\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36m12×6 DataFrames.DataFrame. Omitted printing of 4 columns\n",
      "│ Row │ metric                                     │ Logistic regression │\n",
      "├─────┼────────────────────────────────────────────┼─────────────────────┤\n",
      "│ 1   │ AUPRC                                      │ 0.990361            │\n",
      "│ 2   │ AUROCC                                     │ 0.995607            │\n",
      "│ 3   │ Average precision                          │ 0.990415            │\n",
      "│ 4   │ * Threshold                                │ 0.40199             │\n",
      "│ 5   │ * Accuracy                                 │ 0.97654             │\n",
      "│ 6   │ * Cohen's Kappa statistic                  │ 0.938018            │\n",
      "│ 7   │ [max] * F1 score                           │ 0.968992            │\n",
      "│ 8   │ * Precision (positive predictive value)    │ 0.94697             │\n",
      "│ 9   │ * Negative predictive value                │ 0.995215            │\n",
      "│ 10  │ * Recall (sensitivity, true positive rate) │ 0.992063            │\n",
      "│ 11  │ * Sensitivity (recall, true positive rate) │ 0.992063            │\n",
      "│ 12  │ * Specificity (true negative rate)         │ 0.967442            │\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36m12×6 DataFrames.DataFrame. Omitted printing of 4 columns\n",
      "│ Row │ metric                                     │ Logistic regression │\n",
      "├─────┼────────────────────────────────────────────┼─────────────────────┤\n",
      "│ 1   │ AUPRC                                      │ 0.990361            │\n",
      "│ 2   │ AUROCC                                     │ 0.995607            │\n",
      "│ 3   │ Average precision                          │ 0.990415            │\n",
      "│ 4   │ * Threshold                                │ 0.40199             │\n",
      "│ 5   │ * Accuracy                                 │ 0.97654             │\n",
      "│ 6   │ [max] * Cohen's Kappa statistic            │ 0.938018            │\n",
      "│ 7   │ * F1 Score                                 │ 0.968992            │\n",
      "│ 8   │ * Precision (positive predictive value)    │ 0.94697             │\n",
      "│ 9   │ * Negative predictive value                │ 0.995215            │\n",
      "│ 10  │ * Recall (sensitivity, true positive rate) │ 0.992063            │\n",
      "│ 11  │ * Sensitivity (recall, true positive rate) │ 0.992063            │\n",
      "│ 12  │ * Specificity (true negative rate)         │ 0.967442            │\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36m12×6 DataFrames.DataFrame. Omitted printing of 4 columns\n",
      "│ Row │ metric                                           │ Logistic regression │\n",
      "├─────┼──────────────────────────────────────────────────┼─────────────────────┤\n",
      "│ 1   │ AUPRC                                            │ 0.980282            │\n",
      "│ 2   │ AUROCC                                           │ 0.990163            │\n",
      "│ 3   │ Average precision                                │ 0.980464            │\n",
      "│ 4   │ * Threshold                                      │ 0.313116            │\n",
      "│ 5   │ * Accuracy                                       │ 0.94152             │\n",
      "│ 6   │ * Cohen's Kappa statistic                        │ 0.836242            │\n",
      "│ 7   │ * F1 Score                                       │ 0.918033            │\n",
      "│ 8   │ * Precision (positive predictive value)          │ 0.888889            │\n",
      "│ 9   │ * Negative predictive value                      │ 0.972222            │\n",
      "│ 10  │ * Recall (sensitivity, true positive rate)       │ 0.949153            │\n",
      "│ 11  │ [fix] * Sensitivity (recall, true positive rate) │ 0.949153            │\n",
      "│ 12  │ * Specificity (true negative rate)               │ 0.9375              │\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36m12×6 DataFrames.DataFrame. Omitted printing of 4 columns\n",
      "│ Row │ metric                                     │ Logistic regression │\n",
      "├─────┼────────────────────────────────────────────┼─────────────────────┤\n",
      "│ 1   │ AUPRC                                      │ 0.980282            │\n",
      "│ 2   │ AUROCC                                     │ 0.990163            │\n",
      "│ 3   │ Average precision                          │ 0.980464            │\n",
      "│ 4   │ * Threshold                                │ 0.435877            │\n",
      "│ 5   │ * Accuracy                                 │ 0.94152             │\n",
      "│ 6   │ * Cohen's Kappa statistic                  │ 0.83338             │\n",
      "│ 7   │ * F1 Score                                 │ 0.916667            │\n",
      "│ 8   │ * Precision (positive predictive value)    │ 0.901639            │\n",
      "│ 9   │ * Negative predictive value                │ 0.963636            │\n",
      "│ 10  │ * Recall (sensitivity, true positive rate) │ 0.932203            │\n",
      "│ 11  │ * Sensitivity (recall, true positive rate) │ 0.932203            │\n",
      "│ 12  │ [fix] * Specificity (true negative rate)   │ 0.946429            │\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36m12×6 DataFrames.DataFrame. Omitted printing of 4 columns\n",
      "│ Row │ metric                                     │ Logistic regression │\n",
      "├─────┼────────────────────────────────────────────┼─────────────────────┤\n",
      "│ 1   │ AUPRC                                      │ 0.980282            │\n",
      "│ 2   │ AUROCC                                     │ 0.990163            │\n",
      "│ 3   │ Average precision                          │ 0.980464            │\n",
      "│ 4   │ * Threshold                                │ 0.738787            │\n",
      "│ 5   │ * Accuracy                                 │ 0.959064            │\n",
      "│ 6   │ * Cohen's Kappa statistic                  │ 0.880351            │\n",
      "│ 7   │ [max] * F1 score                           │ 0.940171            │\n",
      "│ 8   │ * Precision (positive predictive value)    │ 0.948276            │\n",
      "│ 9   │ * Negative predictive value                │ 0.964602            │\n",
      "│ 10  │ * Recall (sensitivity, true positive rate) │ 0.932203            │\n",
      "│ 11  │ * Sensitivity (recall, true positive rate) │ 0.932203            │\n",
      "│ 12  │ * Specificity (true negative rate)         │ 0.973214            │\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36m12×6 DataFrames.DataFrame. Omitted printing of 4 columns\n",
      "│ Row │ metric                                     │ Logistic regression │\n",
      "├─────┼────────────────────────────────────────────┼─────────────────────┤\n",
      "│ 1   │ AUPRC                                      │ 0.980282            │\n",
      "│ 2   │ AUROCC                                     │ 0.990163            │\n",
      "│ 3   │ Average precision                          │ 0.980464            │\n",
      "│ 4   │ * Threshold                                │ 0.738787            │\n",
      "│ 5   │ * Accuracy                                 │ 0.959064            │\n",
      "│ 6   │ [max] * Cohen's Kappa statistic            │ 0.880351            │\n",
      "│ 7   │ * F1 Score                                 │ 0.940171            │\n",
      "│ 8   │ * Precision (positive predictive value)    │ 0.948276            │\n",
      "│ 9   │ * Negative predictive value                │ 0.964602            │\n",
      "│ 10  │ * Recall (sensitivity, true positive rate) │ 0.932203            │\n",
      "│ 11  │ * Sensitivity (recall, true positive rate) │ 0.932203            │\n",
      "│ 12  │ * Specificity (true negative rate)         │ 0.973214            │\n",
      "\u001b[39m"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"/tmp/juliaOXo0iH.svg\""
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "cell_type": "code",
   "source": [
    "##### Beginning of file\n",
    "\n",
    "# This file was generated by PredictMD version 0.19.0-DEV\n",
    "# For help, please visit https://www.predictmd.net\n",
    "\n",
    "import PredictMD\n",
    "\n",
    "### Begin project-specific settings\n",
    "\n",
    "PredictMD.require_julia_version(\"v0.6\")\n",
    "\n",
    "PredictMD.require_predictmd_version(\"0.19.0-DEV\")\n",
    "\n",
    "# PredictMD.require_predictmd_version(\"0.19.0-DEV\", \"0.20.0-\")\n",
    "\n",
    "PROJECT_OUTPUT_DIRECTORY = PredictMD.project_directory(\n",
    "    homedir(),\n",
    "    \"Desktop\",\n",
    "    \"breast_cancer_biopsy_example\",\n",
    "    )\n",
    "\n",
    "### End project-specific settings\n",
    "\n",
    "### Begin model comparison code\n",
    "\n",
    "import CSV\n",
    "import Compat\n",
    "import DataFrames\n",
    "import FileIO\n",
    "import JLD2\n",
    "import Knet\n",
    "\n",
    "srand(999)\n",
    "\n",
    "trainingandvalidation_features_df_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"trainingandvalidation_features_df.csv\",\n",
    "    )\n",
    "trainingandvalidation_labels_df_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"trainingandvalidation_labels_df.csv\",\n",
    "    )\n",
    "testing_features_df_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"testing_features_df.csv\",\n",
    "    )\n",
    "testing_labels_df_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"testing_labels_df.csv\",\n",
    "    )\n",
    "training_features_df_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"training_features_df.csv\",\n",
    "    )\n",
    "training_labels_df_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"training_labels_df.csv\",\n",
    "    )\n",
    "validation_features_df_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"validation_features_df.csv\",\n",
    "    )\n",
    "validation_labels_df_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"validation_labels_df.csv\",\n",
    "    )\n",
    "trainingandvalidation_features_df = CSV.read(\n",
    "    trainingandvalidation_features_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "trainingandvalidation_labels_df = CSV.read(\n",
    "    trainingandvalidation_labels_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "testing_features_df = CSV.read(\n",
    "    testing_features_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "testing_labels_df = CSV.read(\n",
    "    testing_labels_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "training_features_df = CSV.read(\n",
    "    training_features_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "training_labels_df = CSV.read(\n",
    "    training_labels_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "validation_features_df = CSV.read(\n",
    "    validation_features_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "validation_labels_df = CSV.read(\n",
    "    validation_labels_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "\n",
    "smoted_training_features_df_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"smoted_training_features_df.csv\",\n",
    "    )\n",
    "smoted_training_labels_df_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"smoted_training_labels_df.csv\",\n",
    "    )\n",
    "smoted_training_features_df = CSV.read(\n",
    "    smoted_training_features_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "smoted_training_labels_df = CSV.read(\n",
    "    smoted_training_labels_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "\n",
    "logistic_classifier_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"logistic_classifier.jld2\",\n",
    "    )\n",
    "random_forest_classifier_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"random_forest_classifier.jld2\",\n",
    "    )\n",
    "c_svc_svm_classifier_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"c_svc_svm_classifier.jld2\",\n",
    "    )\n",
    "nu_svc_svm_classifier_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"nu_svc_svm_classifier.jld2\",\n",
    "    )\n",
    "knet_mlp_classifier_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"knet_mlp_classifier.jld2\",\n",
    "    )\n",
    "\n",
    "logistic_classifier =\n",
    "    PredictMD.load_model(logistic_classifier_filename)\n",
    "random_forest_classifier =\n",
    "    PredictMD.load_model(random_forest_classifier_filename)\n",
    "c_svc_svm_classifier =\n",
    "    PredictMD.load_model(c_svc_svm_classifier_filename)\n",
    "nu_svc_svm_classifier =\n",
    "    PredictMD.load_model(nu_svc_svm_classifier_filename)\n",
    "knet_mlp_classifier =\n",
    "    PredictMD.load_model(knet_mlp_classifier_filename)\n",
    "PredictMD.parse_functions!(knet_mlp_classifier)\n",
    "\n",
    "all_models = PredictMD.Fittable[\n",
    "    logistic_classifier,\n",
    "    random_forest_classifier,\n",
    "    c_svc_svm_classifier,\n",
    "    nu_svc_svm_classifier,\n",
    "    knet_mlp_classifier,\n",
    "    ]\n",
    "\n",
    "single_label_name = :Class\n",
    "negative_class = \"benign\"\n",
    "positive_class = \"malignant\"\n",
    "\n",
    "single_label_levels = [negative_class, positive_class]\n",
    "\n",
    "categorical_label_names = Symbol[single_label_name]\n",
    "continuous_label_names = Symbol[]\n",
    "label_names = vcat(categorical_label_names, continuous_label_names)\n",
    "\n",
    "Compat.@info(PredictMD.singlelabelbinaryclassificationmetrics(\n",
    "    all_models,\n",
    "    training_features_df,\n",
    "    training_labels_df,\n",
    "    single_label_name,\n",
    "    positive_class;\n",
    "    sensitivity = 0.95,\n",
    "    ))\n",
    "Compat.@info(PredictMD.singlelabelbinaryclassificationmetrics(\n",
    "    all_models,\n",
    "    training_features_df,\n",
    "    training_labels_df,\n",
    "    single_label_name,\n",
    "    positive_class;\n",
    "    specificity = 0.95,\n",
    "    ))\n",
    "Compat.@info(PredictMD.singlelabelbinaryclassificationmetrics(\n",
    "    all_models,\n",
    "    training_features_df,\n",
    "    training_labels_df,\n",
    "    single_label_name,\n",
    "    positive_class;\n",
    "    maximize = :f1score,\n",
    "    ))\n",
    "Compat.@info(PredictMD.singlelabelbinaryclassificationmetrics(\n",
    "    all_models,\n",
    "    training_features_df,\n",
    "    training_labels_df,\n",
    "    single_label_name,\n",
    "    positive_class;\n",
    "    maximize = :cohen_kappa,\n",
    "    ))\n",
    "\n",
    "Compat.@info(PredictMD.singlelabelbinaryclassificationmetrics(\n",
    "    all_models,\n",
    "    testing_features_df,\n",
    "    testing_labels_df,\n",
    "    single_label_name,\n",
    "    positive_class;\n",
    "    sensitivity = 0.95,\n",
    "    ))\n",
    "Compat.@info(PredictMD.singlelabelbinaryclassificationmetrics(\n",
    "    all_models,\n",
    "    testing_features_df,\n",
    "    testing_labels_df,\n",
    "    single_label_name,\n",
    "    positive_class;\n",
    "    specificity = 0.95,\n",
    "    ))\n",
    "Compat.@info(PredictMD.singlelabelbinaryclassificationmetrics(\n",
    "    all_models,\n",
    "    testing_features_df,\n",
    "    testing_labels_df,\n",
    "    single_label_name,\n",
    "    positive_class;\n",
    "    maximize = :f1score,\n",
    "    ))\n",
    "Compat.@info(PredictMD.singlelabelbinaryclassificationmetrics(\n",
    "    all_models,\n",
    "    testing_features_df,\n",
    "    testing_labels_df,\n",
    "    single_label_name,\n",
    "    positive_class;\n",
    "    maximize = :cohen_kappa,\n",
    "    ))\n",
    "\n",
    "rocplottesting = PredictMD.plotroccurves(\n",
    "    all_models,\n",
    "    testing_features_df,\n",
    "    testing_labels_df,\n",
    "    single_label_name,\n",
    "    positive_class,\n",
    "    )\n",
    "PredictMD.open_plot(rocplottesting)\n",
    "\n",
    "prplottesting = PredictMD.plotprcurves(\n",
    "    all_models,\n",
    "    testing_features_df,\n",
    "    testing_labels_df,\n",
    "    single_label_name,\n",
    "    positive_class,\n",
    "    )\n",
    "PredictMD.open_plot(prplottesting)\n",
    "\n",
    "### End model comparison code\n",
    "\n",
    "##### End of file"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.4"
  },
  "kernelspec": {
   "name": "julia-0.6",
   "display_name": "Julia 0.6.4",
   "language": "julia"
  }
 },
 "nbformat": 4
}
