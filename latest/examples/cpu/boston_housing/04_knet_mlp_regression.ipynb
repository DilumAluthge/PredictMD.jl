{
 "cells": [
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mStarting to train Knet model. Max epochs: 200.\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mEpoch: 0. Loss (training set): 1751.7722. Loss (validation set): 1717.2460402149204.\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mEpoch: 100. Loss (training set): 66.09934. Loss (validation set): 70.65888652029466.\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mEpoch: 200. Loss (training set): 51.59168. Loss (validation set): 57.197286991194034.\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mFinished training Knet model.\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mStarting to train Knet model. Max epochs: 1000.\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mEpoch: 200. Loss (training set): 51.59168. Loss (validation set): 57.197286991194034.\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mEpoch: 300. Loss (training set): 41.914536. Loss (validation set): 44.88992458655756.\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mEpoch: 400. Loss (training set): 36.16382. Loss (validation set): 35.09895381440636.\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mEpoch: 500. Loss (training set): 29.710537. Loss (validation set): 28.507828887032293.\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mEpoch: 600. Loss (training set): 26.415281. Loss (validation set): 24.21031413051355.\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mEpoch: 700. Loss (training set): 23.775227. Loss (validation set): 21.562710817925204.\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mEpoch: 800. Loss (training set): 21.592096. Loss (validation set): 20.576544393481335.\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mEpoch: 900. Loss (training set): 19.215767. Loss (validation set): 18.187177333907847.\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mEpoch: 1000. Loss (training set): 17.761333. Loss (validation set): 17.03262552517438.\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mFinished training Knet model.\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mAttempting to save model...\n",
      "\u001b[39m\u001b[1m\u001b[36mInfo: \u001b[39m\u001b[22m\u001b[36mSaved model to file \"/tmp/tmptiDaK9/PREDICTMDTEMPDIRECTORY/knet_mlp_regression.jld2\"\n",
      "\u001b[39m"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"/tmp/tmptiDaK9/PREDICTMDTEMPDIRECTORY/knet_mlp_regression.jld2\""
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "cell_type": "code",
   "source": [
    "##### Beginning of file\n",
    "\n",
    "# This file was generated by PredictMD version 0.20.0-DEV\n",
    "# For help, please visit https://www.predictmd.net\n",
    "\n",
    "import PredictMD\n",
    "\n",
    "### Begin project-specific settings\n",
    "\n",
    "PredictMD.require_julia_version(\"v0.6\")\n",
    "\n",
    "PredictMD.require_predictmd_version(\"0.20.0-DEV\")\n",
    "\n",
    "# PredictMD.require_predictmd_version(\"0.20.0-DEV\", \"0.21.0-\")\n",
    "\n",
    "PROJECT_OUTPUT_DIRECTORY = PredictMD.project_directory(\n",
    "    homedir(),\n",
    "    \"Desktop\",\n",
    "    \"boston_housing_example\",\n",
    "    )\n",
    "\n",
    "### End project-specific settings\n",
    "\n",
    "### Begin Knet neural network regression code\n",
    "\n",
    "import CSV\n",
    "import Compat\n",
    "import DataFrames\n",
    "import FileIO\n",
    "import JLD2\n",
    "import Knet\n",
    "\n",
    "srand(999)\n",
    "\n",
    "trainingandvalidation_features_df_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"trainingandvalidation_features_df.csv\",\n",
    "    )\n",
    "trainingandvalidation_labels_df_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"trainingandvalidation_labels_df.csv\",\n",
    "    )\n",
    "testing_features_df_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"testing_features_df.csv\",\n",
    "    )\n",
    "testing_labels_df_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"testing_labels_df.csv\",\n",
    "    )\n",
    "training_features_df_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"training_features_df.csv\",\n",
    "    )\n",
    "training_labels_df_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"training_labels_df.csv\",\n",
    "    )\n",
    "validation_features_df_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"validation_features_df.csv\",\n",
    "    )\n",
    "validation_labels_df_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"validation_labels_df.csv\",\n",
    "    )\n",
    "trainingandvalidation_features_df = CSV.read(\n",
    "    trainingandvalidation_features_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "trainingandvalidation_labels_df = CSV.read(\n",
    "    trainingandvalidation_labels_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "testing_features_df = CSV.read(\n",
    "    testing_features_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "testing_labels_df = CSV.read(\n",
    "    testing_labels_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "training_features_df = CSV.read(\n",
    "    training_features_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "training_labels_df = CSV.read(\n",
    "    training_labels_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "validation_features_df = CSV.read(\n",
    "    validation_features_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "validation_labels_df = CSV.read(\n",
    "    validation_labels_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "\n",
    "categorical_feature_names_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"categorical_feature_names.jld2\",\n",
    "    )\n",
    "continuous_feature_names_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"continuous_feature_names.jld2\",\n",
    "    )\n",
    "categorical_feature_names = FileIO.load(\n",
    "    categorical_feature_names_filename,\n",
    "    \"categorical_feature_names\",\n",
    "    )\n",
    "continuous_feature_names = FileIO.load(\n",
    "    continuous_feature_names_filename,\n",
    "    \"continuous_feature_names\",\n",
    "    )\n",
    "feature_names = vcat(categorical_feature_names, continuous_feature_names)\n",
    "\n",
    "single_label_name = :MedV\n",
    "\n",
    "continuous_label_names = Symbol[single_label_name]\n",
    "categorical_label_names = Symbol[]\n",
    "label_names = vcat(categorical_label_names, continuous_label_names)\n",
    "\n",
    "knet_mlp_predict_function_source = \"\"\"\n",
    "function knetmlp_predict(\n",
    "        w,\n",
    "        x0::AbstractArray,\n",
    "        )\n",
    "    x1 = Knet.relu.( w[1]*x0 .+ w[2] )\n",
    "    x2 = w[3]*x1 .+ w[4]\n",
    "    return x2\n",
    "end\n",
    "\"\"\"\n",
    "\n",
    "knet_mlp_loss_function_source = \"\"\"\n",
    "function knetmlp_loss(\n",
    "        predict_function::Function,\n",
    "        modelweights,\n",
    "        x::AbstractArray,\n",
    "        ytrue::AbstractArray;\n",
    "        L1::Real = Cfloat(0),\n",
    "        L2::Real = Cfloat(0),\n",
    "        )\n",
    "    loss = mean(\n",
    "        abs2,\n",
    "        ytrue - predict_function(\n",
    "            modelweights,\n",
    "            x,\n",
    "            ),\n",
    "        )\n",
    "    if L1 != 0\n",
    "        loss += L1 * sum(sum(abs, w_i) for w_i in modelweights[1:2:end])\n",
    "    end\n",
    "    if L2 != 0\n",
    "        loss += L2 * sum(sum(abs2, w_i) for w_i in modelweights[1:2:end])\n",
    "    end\n",
    "    return loss\n",
    "end\n",
    "\"\"\"\n",
    "\n",
    "feature_contrasts =\n",
    "    PredictMD.generate_feature_contrasts(training_features_df, feature_names)\n",
    "\n",
    "knetmlp_modelweights = Any[\n",
    "    Cfloat.(\n",
    "        0.1f0*randn(Cfloat,10,feature_contrasts.num_array_columns)\n",
    "        ),\n",
    "    Cfloat.(\n",
    "        zeros(Cfloat,10,1)\n",
    "        ),\n",
    "    Cfloat.(\n",
    "        0.1f0*randn(Cfloat,1,10)\n",
    "        ),\n",
    "    Cfloat.(\n",
    "        zeros(Cfloat,1,1),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "knetmlp_losshyperparameters = Dict()\n",
    "knetmlp_losshyperparameters[:L1] = Cfloat(0.0)\n",
    "knetmlp_losshyperparameters[:L2] = Cfloat(0.0)\n",
    "knetmlp_optimizationalgorithm = :Adam\n",
    "knetmlp_optimizerhyperparameters = Dict()\n",
    "knetmlp_minibatchsize = 48\n",
    "\n",
    "knet_mlp_regression = PredictMD.single_labeldataframeknetregression(\n",
    "    feature_names,\n",
    "    single_label_name;\n",
    "    package = :Knet,\n",
    "    name = \"Knet MLP\",\n",
    "    predict_function_source = knet_mlp_predict_function_source,\n",
    "    loss_function_source = knet_mlp_loss_function_source,\n",
    "    losshyperparameters = knetmlp_losshyperparameters,\n",
    "    optimizationalgorithm = knetmlp_optimizationalgorithm,\n",
    "    optimizerhyperparameters = knetmlp_optimizerhyperparameters,\n",
    "    minibatchsize = knetmlp_minibatchsize,\n",
    "    modelweights = knetmlp_modelweights,\n",
    "    maxepochs = 200,\n",
    "    printlosseverynepochs = 100,\n",
    "    feature_contrasts = feature_contrasts,\n",
    "    )\n",
    "\n",
    "PredictMD.parse_functions!(knet_mlp_regression)\n",
    "\n",
    "PredictMD.fit!(\n",
    "    knet_mlp_regression,\n",
    "    training_features_df,\n",
    "    training_labels_df,\n",
    "    validation_features_df,\n",
    "    validation_labels_df,\n",
    "    )\n",
    "\n",
    "PredictMD.set_max_epochs!(knet_mlp_regression, 1_000)\n",
    "\n",
    "PredictMD.fit!(\n",
    "    knet_mlp_regression,\n",
    "    training_features_df,\n",
    "    training_labels_df,\n",
    "    validation_features_df,\n",
    "    validation_labels_df,\n",
    "    )\n",
    "\n",
    "knet_learningcurve_lossvsepoch = PredictMD.plotlearningcurve(\n",
    "    knet_mlp_regression,\n",
    "    :loss_vs_epoch;\n",
    "    )\n",
    "PredictMD.open_plot(knet_learningcurve_lossvsepoch)\n",
    "\n",
    "knet_learningcurve_lossvsepoch_skip10epochs = PredictMD.plotlearningcurve(\n",
    "    knet_mlp_regression,\n",
    "    :loss_vs_epoch;\n",
    "    startat = 10,\n",
    "    endat = :end,\n",
    "    )\n",
    "PredictMD.open_plot(knet_learningcurve_lossvsepoch_skip10epochs)\n",
    "\n",
    "knet_learningcurve_lossvsiteration = PredictMD.plotlearningcurve(\n",
    "    knet_mlp_regression,\n",
    "    :loss_vs_iteration;\n",
    "    window = 50,\n",
    "    sampleevery = 10,\n",
    "    )\n",
    "PredictMD.open_plot(knet_learningcurve_lossvsiteration)\n",
    "\n",
    "knet_learningcurve_lossvsiteration_skip100iterations =\n",
    "    PredictMD.plotlearningcurve(\n",
    "        knet_mlp_regression,\n",
    "        :loss_vs_iteration;\n",
    "        window = 50,\n",
    "        sampleevery = 10,\n",
    "        startat = 100,\n",
    "        endat = :end,\n",
    "        )\n",
    "PredictMD.open_plot(knet_learningcurve_lossvsiteration_skip100iterations)\n",
    "\n",
    "knet_mlp_regression_plot_training =\n",
    "    PredictMD.plotsinglelabelregressiontrueversuspredicted(\n",
    "        knet_mlp_regression,\n",
    "        training_features_df,\n",
    "        training_labels_df,\n",
    "        single_label_name,\n",
    "        )\n",
    "PredictMD.open_plot(knet_mlp_regression_plot_training)\n",
    "\n",
    "knet_mlp_regression_plot_testing =\n",
    "    PredictMD.plotsinglelabelregressiontrueversuspredicted(\n",
    "        knet_mlp_regression,\n",
    "        testing_features_df,\n",
    "        testing_labels_df,\n",
    "        single_label_name,\n",
    "        )\n",
    "PredictMD.open_plot(knet_mlp_regression_plot_testing)\n",
    "\n",
    "PredictMD.singlelabelregressionmetrics(\n",
    "    knet_mlp_regression,\n",
    "    training_features_df,\n",
    "    training_labels_df,\n",
    "    single_label_name,\n",
    "    )\n",
    "\n",
    "PredictMD.singlelabelregressionmetrics(\n",
    "    knet_mlp_regression,\n",
    "    testing_features_df,\n",
    "    testing_labels_df,\n",
    "    single_label_name,\n",
    "    )\n",
    "\n",
    "knet_mlp_regression_filename = joinpath(\n",
    "    PROJECT_OUTPUT_DIRECTORY,\n",
    "    \"knet_mlp_regression.jld2\",\n",
    "    )\n",
    "\n",
    "PredictMD.save_model(knet_mlp_regression_filename, knet_mlp_regression)\n",
    "\n",
    "### End Knet neural network regression code\n",
    "\n",
    "##### End of file"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.4"
  },
  "kernelspec": {
   "name": "julia-0.6",
   "display_name": "Julia 0.6.4",
   "language": "julia"
  }
 },
 "nbformat": 4
}
