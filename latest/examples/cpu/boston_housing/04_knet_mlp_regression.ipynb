{
 "cells": [
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mStarting to train Knet.jl model. Max epochs: 1000.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch: 0. Loss (training set): 1751.7725. Loss (validation set): 1717.2460402149204.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch: 100. Loss (training set): 66.09934. Loss (validation set): 70.65888454908776.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch: 200. Loss (training set): 51.591682. Loss (validation set): 57.197285541622215.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch: 300. Loss (training set): 41.914547. Loss (validation set): 44.88992654763992.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch: 400. Loss (training set): 36.16381. Loss (validation set): 35.09895554782976.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch: 500. Loss (training set): 29.710537. Loss (validation set): 28.507831686788524.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch: 600. Loss (training set): 26.416058. Loss (validation set): 24.191826766418025.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch: 700. Loss (training set): 23.775814. Loss (validation set): 21.54392504220271.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch: 800. Loss (training set): 21.598675. Loss (validation set): 20.519193721460965.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch: 900. Loss (training set): 19.214457. Loss (validation set): 18.209233432557223.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch: 1000. Loss (training set): 17.76278. Loss (validation set): 17.120117709759242.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mFinished training Knet.jl model.\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mDEBUG: Skipping opening file during Travis build: /tmp/juliaeRJX1s.svg\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mDEBUG: Skipping opening file during Travis build: /tmp/juliayQVIkF.svg\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mDEBUG: Skipping opening file during Travis build: /tmp/juliaXhAqDX.svg\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mDEBUG: Skipping opening file during Travis build: /tmp/julia2ocfJj.svg\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mDEBUG: Skipping opening file during Travis build: /tmp/julia7eEdJJ.svg\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mDEBUG: Skipping opening file during Travis build: /tmp/juliaFDWvpd.svg\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mAttempting to save model...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mSaved model to file \"/tmp/boston_housing_example/knet_mlp_regression.jld2\"\n",
      "\u001b[39m"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"/tmp/boston_housing_example/knet_mlp_regression.jld2\""
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "cell_type": "code",
   "source": [
    "# Beginning of file\n",
    "\n",
    "import CSV\n",
    "import DataFrames\n",
    "import Knet\n",
    "import PredictMD\n",
    "\n",
    "srand(999)\n",
    "\n",
    "mkpath(\n",
    "    joinpath(\n",
    "        tempdir(),\n",
    "        \"boston_housing_example\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "trainingandvalidation_features_df_filename = joinpath(\n",
    "    tempdir(),\n",
    "    \"boston_housing_example\",\n",
    "    \"trainingandvalidation_features_df.csv\",\n",
    "    )\n",
    "trainingandvalidation_labels_df_filename = joinpath(\n",
    "    tempdir(),\n",
    "    \"boston_housing_example\",\n",
    "    \"trainingandvalidation_labels_df.csv\",\n",
    "    )\n",
    "testing_features_df_filename = joinpath(\n",
    "    tempdir(),\n",
    "    \"boston_housing_example\",\n",
    "    \"testing_features_df.csv\",\n",
    "    )\n",
    "testing_labels_df_filename = joinpath(\n",
    "    tempdir(),\n",
    "    \"boston_housing_example\",\n",
    "    \"testing_labels_df.csv\",\n",
    "    )\n",
    "training_features_df_filename = joinpath(\n",
    "    tempdir(),\n",
    "    \"boston_housing_example\",\n",
    "    \"training_features_df.csv\",\n",
    "    )\n",
    "training_labels_df_filename = joinpath(\n",
    "    tempdir(),\n",
    "    \"boston_housing_example\",\n",
    "    \"training_labels_df.csv\",\n",
    "    )\n",
    "validation_features_df_filename = joinpath(\n",
    "    tempdir(),\n",
    "    \"boston_housing_example\",\n",
    "    \"validation_features_df.csv\",\n",
    "    )\n",
    "validation_labels_df_filename = joinpath(\n",
    "    tempdir(),\n",
    "    \"boston_housing_example\",\n",
    "    \"validation_labels_df.csv\",\n",
    "    )\n",
    "trainingandvalidation_features_df = CSV.read(\n",
    "    trainingandvalidation_features_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "trainingandvalidation_labels_df = CSV.read(\n",
    "    trainingandvalidation_labels_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "testing_features_df = CSV.read(\n",
    "    testing_features_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "testing_labels_df = CSV.read(\n",
    "    testing_labels_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "training_features_df = CSV.read(\n",
    "    training_features_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "training_labels_df = CSV.read(\n",
    "    training_labels_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "validation_features_df = CSV.read(\n",
    "    validation_features_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "validation_labels_df = CSV.read(\n",
    "    validation_labels_df_filename,\n",
    "    DataFrames.DataFrame;\n",
    "    rows_for_type_detect = 100,\n",
    "    )\n",
    "\n",
    "categoricalfeaturenames = Symbol[]\n",
    "continuousfeaturenames = Symbol[\n",
    "    :Crim,\n",
    "    :Zn,\n",
    "    :Indus,\n",
    "    :Chas,\n",
    "    :NOx,\n",
    "    :Rm,\n",
    "    :Age,\n",
    "    :Dis,\n",
    "    :Rad,\n",
    "    :Tax,\n",
    "    :PTRatio,\n",
    "    :Black,\n",
    "    :LStat,\n",
    "    ]\n",
    "featurenames = vcat(categoricalfeaturenames, continuousfeaturenames)\n",
    "\n",
    "singlelabelname = :MedV\n",
    "labelnames = [singlelabelname]\n",
    "\n",
    "knet_mlp_predict_function_source = \"\"\"\n",
    "function knetmlp_predict(\n",
    "        w,\n",
    "        x0::AbstractArray,\n",
    "        )\n",
    "    x1 = Knet.relu.( w[1]*x0 .+ w[2] )\n",
    "    x2 = w[3]*x1 .+ w[4]\n",
    "    return x2\n",
    "end\n",
    "\"\"\"\n",
    "\n",
    "knet_mlp_loss_function_source = \"\"\"\n",
    "function knetmlp_loss(\n",
    "        predict_function::Function,\n",
    "        modelweights,\n",
    "        x::AbstractArray,\n",
    "        ytrue::AbstractArray;\n",
    "        L1::Real = Cfloat(0),\n",
    "        L2::Real = Cfloat(0),\n",
    "        )\n",
    "    loss = mean(\n",
    "        abs2,\n",
    "        ytrue - predict_function(\n",
    "            modelweights,\n",
    "            x,\n",
    "            ),\n",
    "        )\n",
    "    if L1 != 0\n",
    "        loss += L1 * sum(sum(abs, w_i) for w_i in modelweights[1:2:end])\n",
    "    end\n",
    "    if L2 != 0\n",
    "        loss += L2 * sum(sum(abs2, w_i) for w_i in modelweights[1:2:end])\n",
    "    end\n",
    "    return loss\n",
    "end\n",
    "\"\"\"\n",
    "\n",
    "feature_contrasts =\n",
    "    PredictMD.generate_feature_contrasts(training_features_df, featurenames)\n",
    "\n",
    "knetmlp_modelweights = Any[\n",
    "    Cfloat.(\n",
    "        0.1f0*randn(Cfloat,10,feature_contrasts.num_array_columns)\n",
    "        ),\n",
    "    Cfloat.(\n",
    "        zeros(Cfloat,10,1)\n",
    "        ),\n",
    "    Cfloat.(\n",
    "        0.1f0*randn(Cfloat,1,10)\n",
    "        ),\n",
    "    Cfloat.(\n",
    "        zeros(Cfloat,1,1),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "knetmlp_losshyperparameters = Dict()\n",
    "knetmlp_losshyperparameters[:L1] = Cfloat(0.0)\n",
    "knetmlp_losshyperparameters[:L2] = Cfloat(0.0)\n",
    "knetmlp_optimizationalgorithm = :Adam\n",
    "knetmlp_optimizerhyperparameters = Dict()\n",
    "knetmlp_minibatchsize = 48\n",
    "knetmlp_maxepochs = 1_000\n",
    "\n",
    "knet_mlp_regression = PredictMD.singlelabeldataframeknetregression(\n",
    "    featurenames,\n",
    "    singlelabelname;\n",
    "    package = :Knetjl,\n",
    "    name = \"Knet MLP\",\n",
    "    predict_function_source = knet_mlp_predict_function_source,\n",
    "    loss_function_source = knet_mlp_loss_function_source,\n",
    "    losshyperparameters = knetmlp_losshyperparameters,\n",
    "    optimizationalgorithm = knetmlp_optimizationalgorithm,\n",
    "    optimizerhyperparameters = knetmlp_optimizerhyperparameters,\n",
    "    minibatchsize = knetmlp_minibatchsize,\n",
    "    modelweights = knetmlp_modelweights,\n",
    "    maxepochs = knetmlp_maxepochs,\n",
    "    printlosseverynepochs = 100,\n",
    "    feature_contrasts = feature_contrasts,\n",
    "    )\n",
    "\n",
    "PredictMD.parse_functions!(knet_mlp_regression)\n",
    "\n",
    "PredictMD.fit!(\n",
    "    knet_mlp_regression,\n",
    "    training_features_df,\n",
    "    training_labels_df,\n",
    "    validation_features_df,\n",
    "    validation_labels_df,\n",
    "    )\n",
    "\n",
    "knet_learningcurve_lossvsepoch = PredictMD.plotlearningcurve(\n",
    "    knet_mlp_regression,\n",
    "    :loss_vs_epoch;\n",
    "    )\n",
    "PredictMD.open_plot(knet_learningcurve_lossvsepoch)\n",
    "\n",
    "knet_learningcurve_lossvsepoch_skip10epochs = PredictMD.plotlearningcurve(\n",
    "    knet_mlp_regression,\n",
    "    :loss_vs_epoch;\n",
    "    startat = 10,\n",
    "    endat = :end,\n",
    "    )\n",
    "PredictMD.open_plot(knet_learningcurve_lossvsepoch_skip10epochs)\n",
    "\n",
    "knet_learningcurve_lossvsiteration = PredictMD.plotlearningcurve(\n",
    "    knet_mlp_regression,\n",
    "    :loss_vs_iteration;\n",
    "    window = 50,\n",
    "    sampleevery = 10,\n",
    "    )\n",
    "PredictMD.open_plot(knet_learningcurve_lossvsiteration)\n",
    "\n",
    "knet_learningcurve_lossvsiteration_skip100iterations =\n",
    "    PredictMD.plotlearningcurve(\n",
    "        knet_mlp_regression,\n",
    "        :loss_vs_iteration;\n",
    "        window = 50,\n",
    "        sampleevery = 10,\n",
    "        startat = 100,\n",
    "        endat = :end,\n",
    "        )\n",
    "PredictMD.open_plot(knet_learningcurve_lossvsiteration_skip100iterations)\n",
    "\n",
    "knet_mlp_regression_plot_training =\n",
    "    PredictMD.plotsinglelabelregressiontrueversuspredicted(\n",
    "        knet_mlp_regression,\n",
    "        training_features_df,\n",
    "        training_labels_df,\n",
    "        singlelabelname,\n",
    "        )\n",
    "PredictMD.open_plot(knet_mlp_regression_plot_training)\n",
    "\n",
    "knet_mlp_regression_plot_testing =\n",
    "    PredictMD.plotsinglelabelregressiontrueversuspredicted(\n",
    "        knet_mlp_regression,\n",
    "        testing_features_df,\n",
    "        testing_labels_df,\n",
    "        singlelabelname,\n",
    "        )\n",
    "PredictMD.open_plot(knet_mlp_regression_plot_testing)\n",
    "\n",
    "PredictMD.singlelabelregressionmetrics(\n",
    "    knet_mlp_regression,\n",
    "    training_features_df,\n",
    "    training_labels_df,\n",
    "    singlelabelname,\n",
    "    )\n",
    "\n",
    "PredictMD.singlelabelregressionmetrics(\n",
    "    knet_mlp_regression,\n",
    "    testing_features_df,\n",
    "    testing_labels_df,\n",
    "    singlelabelname,\n",
    "    )\n",
    "\n",
    "knet_mlp_regression_filename = joinpath(\n",
    "    tempdir(),\n",
    "    \"boston_housing_example\",\n",
    "    \"knet_mlp_regression.jld2\",\n",
    "    )\n",
    "\n",
    "PredictMD.save_model(knet_mlp_regression_filename, knet_mlp_regression)\n",
    "\n",
    "# End of file"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.3"
  },
  "kernelspec": {
   "name": "julia-0.6",
   "display_name": "Julia 0.6.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
